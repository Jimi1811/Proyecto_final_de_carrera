# Introduccion
@techreport{FAO,
    author			= {FAO},
    title			= {El estado mundial de la pesca y la acuicultura 2022.},
    institution		= {FAO},
    type			= {}, 
    
    number			= {},
    address			= {Roma},
    year			= {2022},
    month			= {},
    note			= {},
    language        = {spanish},
}

@inbook{Entrevistas_Blume,
	author			= {Blume},
	
	title			= {Keypoints de entrevistas a empresas acuícolas.},
	chapter			= {},
	pages			= {},
	publisher		= {Editor},
	volume			= {},
	
	series			= {},
	type			= {},
	address			= {Lima},
	edition			= {},
	year			= {2023},
	month			= {},
	note			= {},
    language        = {spanish},
}

# Empresas

@misc{AKVAgroup,
  author       = {AKVA Group},
  title        = {AKVA FNC8: A powerful remote net cleaning rig},
  howpublished = {Disponible en \url{https://www.akvagroup.com/sea-based/marine-infrastructure/net-cleaning/akva-fnc8}},
  year 		   = {2023},
}

@misc{DeepTrekker,
  author       = {Deep Trekker Inc.},
  title        = {Aquaculture ROVs for Net Inspections, Patching, Mort Pushing and Site Selection},
  howpublished = {Disponible en \url{https://www.deeptrekker.com/industries/aquaculture}},
  year 		   = {2023},
}

@misc{InnovaSea,
  author       = {Innovasea Systems Inc.},
  title        = {Open Ocean Aquaculture},
  howpublished = {Disponible en \url{https://www.innovasea.com/open-ocean-aquaculture/}},
  year 		   = {2023},
}

@misc{Watbots,
  author       = {Watbots},
  title        = {Watbot cleaning robot},
  howpublished = {Disponible en \url{https://vimeo.com/591091267}},
  year         = {2022},
}

# Articulos
@article{cite:Betancourt,
	abstract = {This paper reports the integration of a remotely operated vehicle (ROV) solution for monitoring water quality in fish farms. The robotic system includes a RGB camera for real-time video capturing and a set of integrated sensors to measure hydro-climatic data. Computer vision algorithms were implemented with the aim of inspecting net-cages in fish farms. A comprehensive software solution was developed to allow a seamless use of the vision algorithms proposed in this work. Our system was designed to process underwater imagery captured by the ROV in order to determine net patterns associated with net failure. The system was tested in a dam under real conditions. ROC data were computed to demonstrate the accuracy of the proposed system during underwater fish cage inspection. On average, we obtained an accuracy of 0.91 regarding net pattern reconstruction tasks, while an accuracy of 0.79 for net damage detection under different underwater scenarios.},
	author = {Betancourt, J. and Coral, W. and Colorado, J.},
	date = {2020/11/05},
	date-added = {2023-07-10 23:51:33 -0500},
	date-modified = {2023-07-10 23:51:33 -0500},
	doi = {10.1007/s42452-020-03623-z},
	id = {Betancourt2020},
	isbn = {2523-3971},
	journal = {SN Applied Sciences},
	number = {12},
	pages = {1946},
	title = {An integrated ROV solution for underwater net-cage inspection in fish farms using computer vision},
	url = {https://doi.org/10.1007/s42452-020-03623-z},
	volume = {2},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1007/s42452-020-03623-z}}


@article{cite:Zhao,
	abstract = {For offshore aquaculture cages, structural damage can cause serious economic property damage to the aquaculture industry, thus it is necessary to carry out regular inspections of the cage structure. At present, the main method of detecting netting damage is that the staff sneak into the water for manual investigation. This method not only does not guarantee personal safety, but is also labor-intensive and inefficient. This paper proposes a new feature curve method for non-contact underwater netting damage detection, which can effectively recognize damaged netting and analyze the degree of damage for the underwater net and return to its damage position. The new method presented in this paper was designed taking into consideration of effect of seaweed growth: Firstly, an image block within the ROI (region of interest) region was processed by bilateral filter. Secondly, the binary image was obtained via the OSTU (the maximum inter-class variance method) method and connected domain detection was performed. Thirdly, the feature gradient histogram was calculated according to the area of the mesh hole and the local peaks of the curve (named as feature curve) was searched to determine the position of damage in the netting. The proposed method combined the image processing technology with aquaculture engineering seamlessly, and reduced the complexity of the detection system greatly, and significantly improved the efficiency of the netting detection. Finally, the MATLAB program was developed to realize the netting detection process and the proposed method had been verified by the actual underwater netting experiment. The experimental results showed that the netting damage detection method proposed in this paper can successfully detect crack of the netting despite image degradation in water.},
	author = {Yun-Peng Zhao and Li-Juan Niu and Hai Du and Chun-Wei Bi},
	doi = {https://doi.org/10.1016/j.aquaeng.2020.102071},
	issn = {0144-8609},
	journal = {Aquacultural Engineering},
	keywords = {Cage culture, Cage net crack, Damage detection, Vision-based detecting method},
	pages = {102071},
	title = {An adaptive method of damage detection for fishing nets based on image processing technology},
	url = {https://www.sciencedirect.com/science/article/pii/S0144860919301876},
	volume = {90},
	year = {2020},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0144860919301876},
	bdsk-url-2 = {https://doi.org/10.1016/j.aquaeng.2020.102071}}


@article{cite:Zhang,
	article-number = {996},
	author = {Zhang, Ziliang and Gui, Fukun and Qu, Xiaoyu and Feng, Dejun},
	doi = {10.3390/jmse10070996},
	issn = {2077-1312},
	journal = {Journal of Marine Science and Engineering},
	number = {7},
	title = {Netting Damage Detection for Marine Aquaculture Facilities Based on Improved Mask R-CNN},
	url = {https://www.mdpi.com/2077-1312/10/7/996},
	volume = {10},
	year = {2022},
	bdsk-url-1 = {https://www.mdpi.com/2077-1312/10/7/996},
	bdsk-url-2 = {https://doi.org/10.3390/jmse10070996}}

@techreport{cite:Ferrera,
  author      = {Maxime Ferrera},
  institution = {Université de Montpellier},
  title       = {Monocular Visual-Inertial-Pressure Fusion for Underwater Localization and 3D Mapping},
  year        = {2019},
}


@article{cite:Schellewald,
  author          = {Christian Schellewald and Annette Stahl},
  journal         = {IFAC-PapersOnLine},
  number          = {S/N},
  title           = {Irregularity detection in net pens exploiting Computer Vision},
  volume          = {S/V},
  year            = {2022},
}


@inproceedings{cite:Chalkiadakis,
  author          = {V. Chalkiadakis and N. Papandroulakis and G. Livanos and K. Moirogiorgou and G. Giakos and M. Zervakis},
  booktitle       = {2017 IEEE International Conference on Imaging Systems and Techniques (IST)},
  editor          = {},
  title           = {Designing a small-sized autonomous underwater vehicle architecture for regular periodic fish-cage net inspection},
  year            = {2017},
}


@article{cite:Liao,
	author = {Wenxuan Liao and Shubin Zhang and Yinghao Wu and Dong An and Yaoguang Wei},
	journal = {Aquacultural Engineering},
	pages = {102219},
	title = {Research on intelligent damage detection of far-sea cage based on machine vision and deep learning},
	url = {https://www.sciencedirect.com/science/article/pii/S0144860921000753},
	volume = {96},
	year = {2022},
}

@article{cite:Labra,
title = {Robust automatic net damage detection and tracking on real aquaculture environment using computer vision},
journal = {Aquacultural Engineering},
volume = {101},
pages = {102323},
year = {2023},
author = {Julio Labra and Marcos D. Zuniga and Javier Rebolledo and Mohamed A. Ahmed and Rodrigo Carvajal and Nicolás Jara and Gonzalo Carvajal},
}

@article{cite:Campos,
  TITLE = {{A Surface Reconstruction Method for In-Detail Underwater 3D Optical Mapping}},
  AUTHOR = {Campos, Ricard and Garcia, Rafael and Alliez, Pierre and Yvinec, Mariette},
  URL = {https://inria.hal.science/hal-01030845},
  JOURNAL = {{The International Journal of Robotics Research}},
  PUBLISHER = {{SAGE Publications}},
  VOLUME = {34},
  NUMBER = {1},
  PAGES = {25},
  YEAR = {2015},
  MONTH = Jan,
  DOI = {10.1177/0278364914544531},
  KEYWORDS = {surface reconstruction},
  PDF = {https://inria.hal.science/hal-01030845/file/underwater.pdf},
  HAL_ID = {hal-01030845},
  HAL_VERSION = {v1},
}

@INPROCEEDINGS{cite:Livianos,
  author={Livanos, George and Zervakis, Michalis and Chalkiadakis, Vaggelis and Moirogiorgou, Konstantia and Giakos, George and Papandroulakis, Nikos},
  booktitle={2018 IEEE International Conference on Imaging Systems and Techniques (IST)}, 
  title={Intelligent Navigation and Control of a Prototype Autonomous Underwater Vehicle for Automated Inspection of Aquaculture net pen cages}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/IST.2018.8577180}}

@article{cite:Paspalakis,
  author          = {Stavros Paspalakis and Konstantia Moirogiorgou and Nikos Papandroulakis and George Giakos and Michalis Zervakis},
  journal         = {IET Image processing},
  number          = {10},
  title           = {Automated fish cage net inspection using image processing techniques},
  volume          = {14},
  year            = {2020}
}

@ARTICLE{cite:Yang,
  author={Yang, Miao and Sowmya, Arcot and Wei, ZhiQiang and Zheng, Bing},
  journal={IEEE Journal of Oceanic Engineering}, 
  title={Offshore Underwater Image Restoration Using Reflection-Decomposition-Based Transmission Map Estimation}, 
  year={2020},
  volume={45},
  number={2},
  pages={521-533},
  doi={10.1109/JOE.2018.2886093}}

@INPROCEEDINGS{cite:Aulinas,
  author={Aulinas, Josep and Carreras, Marc and Llado, Xavier and Salvi, Joaquim and Garcia, Rafael and Prados, Ricard and Petillot, Yvan R.},
  booktitle={OCEANS 2011 IEEE - Spain}, 
  title={Feature extraction for underwater visual SLAM}, 
  year={2011},
  volume={},
  number={},
  pages={1-7},
  doi={10.1109/Oceans-Spain.2011.6003474}}

@article{cite:Macario,
  author          = {A. Macario and M. Michel and Y. Moline and G. Corre and F. Carrel},
  journal         = {Robotics},
  number          = {1},
  title           = {A Comprehensive Survey of Visual SLAM Algorithms},
  volume          = {11},
  year            = {2022},
  doi             = {https://doi.org/10.3390/robotics11010024},
}

@book{cite:Gao,
  author         = {Xiang Gao and Tao Zhang},
  editor         = {},
  publisher      = {Springer Singapore},
  title          = {Introduction to Visual SLAM: From Theory to Practice},
  year           = {2021},
  doi            = {https://doi.org/10.1007/978-981-16-4939-4}
}

@book{cite:gonzalez,
  title={Digital Image Processing},
  author={Gonzalez, R.C. and Woods, R.E.},
  isbn={9780133356724},
  lccn={2017001581},
  url={https://books.google.com.pe/books?id=0F05vgAACAAJ},
  year={2018},
  publisher={Pearson}
}
@misc{matterport_maskrcnn_2017,
  title={Mask R-CNN for object detection and instance segmentation on Keras and TensorFlow},
  author={Waleed Abdulla},
  year={2017},
  publisher={Github},
  journal={GitHub repository},
  howpublished={\url{https://github.com/matterport/Mask_RCNN}},
}

@article{cite:Kaiming,
  author       = {Kaiming He and
                  Xiangyu Zhang and
                  Shaoqing Ren and
                  Jian Sun},
  title        = {Deep Residual Learning for Image Recognition},
  journal      = {CoRR},
  volume       = {abs/1512.03385},
  year         = {2015},
  url          = {http://arxiv.org/abs/1512.03385},
  eprinttype    = {arXiv},
  eprint       = {1512.03385},
  timestamp    = {Wed, 25 Jan 2023 11:01:16 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{cite:Tsung,
  author       = {Tsung{-}Yi Lin and
                  Piotr Doll{\'{a}}r and
                  Ross B. Girshick and
                  Kaiming He and
                  Bharath Hariharan and
                  Serge J. Belongie},
  title        = {Feature Pyramid Networks for Object Detection},
  journal      = {CoRR},
  volume       = {abs/1612.03144},
  year         = {2016},
  url          = {http://arxiv.org/abs/1612.03144},
  eprinttype    = {arXiv},
  eprint       = {1612.03144},
  timestamp    = {Mon, 13 Aug 2018 16:48:50 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/LinDGHHB16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{murTRO2015,
  title={{ORB-SLAM}: a Versatile and Accurate Monocular {SLAM} System},
  author={Mur-Artal and Ra\'ul, Montiel and J. M. M. and Tard\'os and Juan D.},
  journal={IEEE Transactions on Robotics},
  volume={31},
  number={5},
  pages={1147--1163},
  doi = {10.1109/TRO.2015.2463671},
  year={2015}
 }